{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104491,"databundleVersionId":12585144,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv\")\ndf ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Step 2: Identify date columns\ndate_cols = [col for col in df.columns if col.endswith('_N')]\n\n# Step 3: Convert date columns to numeric (if any garbage strings)\ndf[date_cols] = df[date_cols].apply(pd.to_numeric, errors='coerce')\n\n# Step 4: Calculate 1 single overall mean per class\nclass_means = df.groupby('class')[date_cols].apply(lambda x: x.stack().mean())\n\n# Now:\n# class_means['forest'] ‚Üí single float value for forest\n# class_means['impervious'] ‚Üí single float value for impervious\n\n# Step 5: Function to fill NaNs using class-specific value\ndef fill_with_class_mean(row):\n    class_type = row['class']\n    mean_value = class_means[class_type]\n    row[date_cols] = row[date_cols].fillna(mean_value).infer_objects(copy=False)\n    return row\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n# Step 6: Apply to DataFrame\ndf = df.apply(fill_with_class_mean, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df[df['class'] == 'forest'][date_cols].apply(lambda x: x.nunique(), axis=1).max())  # should be 1 if all same\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install imbalanced-learn==0.11.0 --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Assume df is already defined and cleaned\n\n# Identify reflectance columns\ndate_cols = [col for col in df.columns if col.endswith('_N')]\n\n# Fill missing values temporarily to allow SMOTE\nX = df[date_cols].fillna(df[date_cols].mean())\ny = df['class']\n\n# Apply SMOTE\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# New balanced DataFrame\ndf_resampled = pd.DataFrame(X_resampled, columns=date_cols)\ndf_resampled['class'] = y_resampled\nprint(df_balanced['class'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Check class distribution\nclass_counts = df['class'].value_counts()\nprint(class_counts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Step 1: Separate features and target\nX = df_balanced[date_cols]\ny = df_balanced['class']\n\n# Step 2: Initialize and fit-transform StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Step 3: Convert scaled features back to DataFrame\nX_scaled_df = pd.DataFrame(X_scaled, columns=date_cols)\n\n# Step 4: Add class column back\ndf_scaled = X_scaled_df.copy()\ndf_scaled['class'] = y.values\n\n# Step 5: (Optional) Check final resul\ndf_scaled","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Separate features and class\nX = df_scaled[date_cols]\ny = df_scaled['class']\n\n# Step 2: Calculate IQR for each column\nQ1 = X.quantile(0.25)\nQ3 = X.quantile(0.75)\nIQR = Q3 - Q1\n\n# Step 3: Detect outliers in a boolean DataFrame\noutlier_mask = (X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))\n\nclass_means = df_scaled.groupby('class')[date_cols].mean()\n\nX_corrected = X.copy()\nfor col in date_cols:\n    for idx in X.index:\n        if outlier_mask.loc[idx, col]:\n            class_type = y.loc[idx]\n            X_corrected.loc[idx, col] = class_means.loc[class_type, col]\n\ndf_corrected = X_corrected.copy()\ndf_corrected['class'] = y.values\n\n# Step 7: (Optional) Check how many were replaced\ntotal_outliers = outlier_mask.sum().sum()\nprint(f\"Total outlier cells replaced: {total_outliers}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Step 1: Features and Labels\nX_final = X_corrected  # Already scaled and cleaned\ny_final = y            # Class labels\n\n# Step 2: Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42, stratify=y_final)\n\n# Step 3: Initialize and Train the Model\nmodel = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')\nmodel.fit(X_train, y_train)\n\n# Step 4: Predictions\ny_pred = model.predict(X_test)\n\n# Step 5: Evaluation\nprint(\"üîç Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"‚úÖ Accuracy Score:\", accuracy_score(y_test, y_pred))\nprint(\"üìâ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv\")\ntest_data.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Prepare test data\ntest_ids = test_data['ID']                          # Keep IDs for final output\ntest_features = test_data.drop(['Unnamed: 0', 'ID'], axis=1)\n\n# Step 2: Scale using the trained scaler\ntest_scaled = scaler.transform(test_features)     # Use SAME scaler from training\n\n# Step 3: Predict using the trained model\ntest_preds = model.predict(test_scaled)\n\n# Step 4: Create final output DataFrame\noutput_df = pd.DataFrame({\n    'ID': test_ids,\n    'Predicted_Class': test_preds\n})\noutput_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}